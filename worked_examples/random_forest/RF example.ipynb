{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Example\n",
    "For this notebook I'll be pulling some data from Materials Project. I'll use the old api using my MyPymatgen virtual environment\n",
    "\n",
    "Let's start by getting our API key loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taylo\\miniconda3\\envs\\MyPymatgen\\lib\\site-packages\\pymatgen\\ext\\matproj_legacy.py:164: UserWarning: You are using the legacy MPRester. This version of the MPRester will no longer be updated. To access the latest data with the new MPRester, obtain a new API key from https://materialsproject.org/api and consult the docs at https://docs.materialsproject.org/ for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "import os\n",
    "\n",
    "filename = r'G:\\My Drive\\teaching\\5540-6640 Materials Informatics\\old_apikey.txt'\n",
    "\n",
    "def get_file_contents(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            # It's assumed our file contains a single line,\n",
    "            # with our API key\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(\"'%s' file not found\" % filename)\n",
    "\n",
    "\n",
    "Sparks_API = get_file_contents(filename)\n",
    "mpr = MPRester(Sparks_API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grab some data to work with. We'll grab chlorides within 1 meV of the convex hull."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1852/1852 [00:00<00:00, 1909.23it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=('pretty_formula', 'band_gap',\n",
    "                           \"density\", 'formation_energy_per_atom', 'volume'))\n",
    "\n",
    "# grab some props for stable chlorides\n",
    "criteria = {'e_above_hull': {'$lte': 0.001},'elements':{'$all':['Cl']}}\n",
    "# criteria2 = {'e_above_hull': {'$lte': 0.02},'elements':{'$all':['O']},\n",
    "#              'band_gap':{'$ne':0}}\n",
    "\n",
    "props = ['pretty_formula', 'band_gap', \"density\",\n",
    "         'formation_energy_per_atom', 'volume']\n",
    "entries = mpr.query(criteria=criteria, properties=props)\n",
    "\n",
    "i = 0\n",
    "for entry in entries:\n",
    "    df.loc[i] = [entry['pretty_formula'], entry['band_gap'], entry['density'],\n",
    "                 entry['formation_energy_per_atom'], entry['volume']]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is 0.18536192699439857\n",
      "the mean absolute error is 1.0249304272976656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taylo\\miniconda3\\envs\\MyPymatgen\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pretty_formula</th>\n",
       "      <th>band_gap</th>\n",
       "      <th>density</th>\n",
       "      <th>formation_energy_per_atom</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ba2NCl</td>\n",
       "      <td>1.2806</td>\n",
       "      <td>4.677565</td>\n",
       "      <td>-1.545307</td>\n",
       "      <td>115.060598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NbCl2O</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>3.256205</td>\n",
       "      <td>-2.229575</td>\n",
       "      <td>183.394154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cs2NaBiCl6</td>\n",
       "      <td>3.7845</td>\n",
       "      <td>3.488525</td>\n",
       "      <td>-1.964548</td>\n",
       "      <td>338.197782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CsCaCl3</td>\n",
       "      <td>5.3829</td>\n",
       "      <td>2.836287</td>\n",
       "      <td>-2.631981</td>\n",
       "      <td>163.544469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ce2NCl3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.611649</td>\n",
       "      <td>-2.387869</td>\n",
       "      <td>288.490339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>Cs2PbClF6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.197868</td>\n",
       "      <td>-2.347700</td>\n",
       "      <td>246.222537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>K2BrCl6F</td>\n",
       "      <td>1.2492</td>\n",
       "      <td>2.495320</td>\n",
       "      <td>-1.147643</td>\n",
       "      <td>259.408110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>KAgCl3</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.142815</td>\n",
       "      <td>-1.383321</td>\n",
       "      <td>267.694339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>RbSrCl3</td>\n",
       "      <td>5.3613</td>\n",
       "      <td>2.479917</td>\n",
       "      <td>-2.629091</td>\n",
       "      <td>374.232208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>CaTlCl3</td>\n",
       "      <td>4.2085</td>\n",
       "      <td>3.932114</td>\n",
       "      <td>-2.217492</td>\n",
       "      <td>296.304102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1852 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pretty_formula  band_gap   density  formation_energy_per_atom      volume\n",
       "0            Ba2NCl    1.2806  4.677565                  -1.545307  115.060598\n",
       "1            NbCl2O    0.9322  3.256205                  -2.229575  183.394154\n",
       "2        Cs2NaBiCl6    3.7845  3.488525                  -1.964548  338.197782\n",
       "3           CsCaCl3    5.3829  2.836287                  -2.631981  163.544469\n",
       "4           Ce2NCl3    0.0000  4.611649                  -2.387869  288.490339\n",
       "...             ...       ...       ...                        ...         ...\n",
       "1847      Cs2PbClF6    0.0000  4.197868                  -2.347700  246.222537\n",
       "1848       K2BrCl6F    1.2492  2.495320                  -1.147643  259.408110\n",
       "1849         KAgCl3    0.0000  3.142815                  -1.383321  267.694339\n",
       "1850        RbSrCl3    5.3613  2.479917                  -2.629091  374.232208\n",
       "1851        CaTlCl3    4.2085  3.932114                  -2.217492  296.304102\n",
       "\n",
       "[1852 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RNG_SEED = 42\n",
    "np.random.seed(seed=RNG_SEED)\n",
    "\n",
    "X = df[['band_gap','formation_energy_per_atom','volume']]\n",
    "y = df['density']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RNG_SEED)\n",
    "rf = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('the r2 score is',r2)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('the mean absolute error is',mae)\n",
    "rmse_val = mean_squared_error(y_test, y_pred, squared=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model isn't too great alone, but what if we add CBFV features? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 1852/1852 [00:00<00:00, 4684.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 1852/1852 [00:00<00:00, 4516.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Your data contains formula with exotic elements. These were skipped.\n",
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 1852/1852 [00:00<00:00, 4324.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 1852/1852 [00:00<00:00, 5049.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Your data contains formula with exotic elements. These were skipped.\n",
      "\tCreating Pandas Objects...\n",
      "the r2 score is 0.8944746593888349\n",
      "the mean absolute error is 0.3367281499694079\n",
      "Training time: 0.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taylo\\miniconda3\\envs\\MyPymatgen\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from CBFV import composition\n",
    "import time\n",
    "\n",
    "rename_dict = {'density': 'target', 'pretty_formula':'formula'}\n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "\n",
    "RNG_SEED = 42\n",
    "np.random.seed(seed=RNG_SEED)\n",
    "\n",
    "X = df[['formula','band_gap','formation_energy_per_atom','volume']]\n",
    "y = df['target']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RNG_SEED)\n",
    "\n",
    "X_train, y_train, formulae_train, skipped_train = composition.generate_features(df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_test, y_test, formulae_train, skipped_train = composition.generate_features(df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "\n",
    "\n",
    "#technically we should scale and normalize our data here... but lets skip it for now\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Calculate the training time\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "rf = RandomForestRegressor(max_depth=4, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('the r2 score is',r2)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('the mean absolute error is',mae)\n",
    "rmse_val = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Training time:\", training_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way better! Our R^2 went way up, and our MAE went way down.\n",
    "\n",
    "# Grid Search Hyperparameter Tuning\n",
    "\n",
    "Now let's try one more time, but this time we'll do hyperparameter tuning!\n",
    "Note- we're going to reduce our data down to just 300 points during hyperparameter tuning or it will take foreeeeeeevvvvveeerrr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 300/300 [00:00<00:00, 8329.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 300/300 [00:00<00:00, 4833.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Your data contains formula with exotic elements. These were skipped.\n",
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 300/300 [00:00<00:00, 10118.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 300/300 [00:00<00:00, 6011.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: Your data contains formula with exotic elements. These were skipped.\n",
      "\tCreating Pandas Objects...\n",
      "Best parameters (subset): {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score (subset): 0.8394707414271082\n",
      "R2 score (subset): 0.9583743933545354\n",
      "Mean absolute error (subset): 0.21237463359695635\n",
      "Root mean squared error (subset): 0.29315146182796753\n",
      "Training time (subset): 2006.5857346057892 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taylo\\miniconda3\\envs\\MyPymatgen\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "# Select a subset of the dataframe with 300 data points\n",
    "subset_df = df.sample(n=300, random_state=RNG_SEED)\n",
    "\n",
    "# Split the subset into training and testing sets\n",
    "rename_dict = {'density': 'target', 'pretty_formula':'formula'}\n",
    "subset_df = subset_df.rename(columns=rename_dict)\n",
    "RNG_SEED = 42\n",
    "np.random.seed(seed=RNG_SEED)\n",
    "X = subset_df[['formula','band_gap','formation_energy_per_atom','volume']]\n",
    "y = subset_df['target']\n",
    "\n",
    "#now do CBFV\n",
    "X_train, y_train, formulae_train, skipped_train = composition.generate_features(subset_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_test, y_test, formulae_train, skipped_train = composition.generate_features(subset_df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "\n",
    "\n",
    "# Define the parameter grid for the grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Create the random forest regressor\n",
    "rf_subset = RandomForestRegressor(random_state=RNG_SEED)\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search_subset = GridSearchCV(estimator=rf_subset, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Start the timer\n",
    "start_time_subset = time.time()\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_subset.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training time\n",
    "training_time_subset = time.time() - start_time_subset\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_subset = grid_search_subset.best_params_\n",
    "best_score_subset = grid_search_subset.best_score_\n",
    "\n",
    "# Train the model with the best parameters\n",
    "rf_best_subset_grid = RandomForestRegressor(random_state=RNG_SEED, **best_params_subset)\n",
    "rf_best_subset_grid.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_subset = rf_best_subset_grid.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_subset = r2_score(y_test, y_pred_subset)\n",
    "mae_subset = mean_absolute_error(y_test, y_pred_subset)\n",
    "rmse_subset = mean_squared_error(y_test, y_pred_subset, squared=False)\n",
    "\n",
    "print(\"Best parameters (subset):\", best_params_subset)\n",
    "print(\"Best score (subset):\", best_score_subset)\n",
    "print(\"R2 score (subset):\", r2_subset)\n",
    "print(\"Mean absolute error (subset):\", mae_subset)\n",
    "print(\"Root mean squared error (subset):\", rmse_subset)\n",
    "print(\"Training time (subset):\", training_time_subset, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random search hyperparameter tuning\n",
    "Now let's try random search hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import time\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Create the random forest regressor\n",
    "rf_subset = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Create the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(estimator=rf_subset, param_distributions=param_grid, n_iter=10, cv=5, random_state=0)\n",
    "\n",
    "# Start the timer\n",
    "start_time_subset = time.time()\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search_subset.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training time\n",
    "training_time_subset = time.time() - start_time_subset\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_subset = grid_search_subset.best_params_\n",
    "best_score_subset = grid_search_subset.best_score_\n",
    "\n",
    "# Train the model with the best parameters\n",
    "rf_best_subset_random = RandomForestRegressor(random_state=RNG_SEED, **best_params_subset)\n",
    "rf_best_subset_random.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_subset = rf_best_subset_random.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2_subset = r2_score(y_test, y_pred_subset)\n",
    "mae_subset = mean_absolute_error(y_test, y_pred_subset)\n",
    "rmse_subset = mean_squared_error(y_test, y_pred_subset, squared=False)\n",
    "\n",
    "print(\"Best parameters (subset):\", best_params_subset)\n",
    "print(\"Best score (subset):\", best_score_subset)\n",
    "print(\"R2 score (subset):\", r2_subset)\n",
    "print(\"Mean absolute error (subset):\", mae_subset)\n",
    "print(\"Root mean squared error (subset):\", rmse_subset)\n",
    "print(\"Training time (subset):\", training_time_subset, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#featurize with all the data, not just the subset\n",
    "X_train, y_train, formulae_train, skipped_train = composition.generate_features(df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_test, y_test, formulae_train, skipped_train = composition.generate_features(df, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model with the best parameters\n",
    "rf_best_subset_random.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the training time\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = rf_best_subset_random.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print(\"R2 score:\", r2)\n",
    "print(\"Mean absolute error:\", mae)\n",
    "print(\"Root mean squared error:\", rmse)\n",
    "print(\"Training time:\", training_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree visualization\n",
    "Finally, we can do tree visualization with graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "feature_list = list(X_train.columns)\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost and others\n",
    "\n",
    "There are many other variants of random forests. Adaboost, XGBoost etc. XGBoost, in particular, has emerged as one of the favorite and best classical models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
