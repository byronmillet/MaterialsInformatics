{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Structural features\n",
    "**1.1 cif-cn-featurizer**\n",
    "\n",
    "Our friend Anton Oliynyk has recently released a new python script `cif-cn-featurizer`. \n",
    "\n",
    "Here is their description \"A Python script designed to process CIF (Crystallographic Information File) files and extract various features from them. These features include interatomic distances, atomic environment information, and coordination numbers. The script can handle binary and ternary compounds.\"\n",
    "\n",
    "Let's test it out and see how it works! To do so we will need some cifs. Right now the featurizer only works with binaries made up of certain elements shown in this plot. \n",
    "\n",
    "![allowed elements](https://github.com/sp8rks/MaterialsInformatics/blob/main/HW/HW2/cif-cn-featurizer-allowed-elements.png?raw=true)\n",
    "\n",
    "**<font color='teal'>a)</font>** Download the `cif-cn-featurizer` files and run it on the cif files in the `HW\\cn-featurizer\\cifs` folder. \n",
    "\n",
    "Note: in case you can't get it working, you'll also find a csv folder with all the extracted features for these cifs already complete, but try and get it working so you can use it in the future!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Byron Notes on the running of the featurizer code:\n",
    "\n",
    "I used conda install -c conda-forge for all installs in my environment\n",
    "\n",
    "cif-cn-featurizer Github prereqs advised to install:\n",
    "    -   Click\n",
    "    -   Pandas\n",
    "    -   Gemmi\n",
    "\n",
    "main.py then failed to run due to missing Scipy\n",
    "\n",
    "Installed scipy\n",
    "main.py failed due to missing sympy\n",
    "\n",
    "Installed sympy\n",
    "The script ran, but when selecting the folder cif_test from the cloned repository, it errored with missing openpyxl dependency\n",
    "\n",
    "Installed openpyxl\n",
    "The script ran on their cif_test set without issues\n",
    "Their test set was only one AlSb.cif\n",
    "\n",
    "**Try using pip install for the Github prereqs - does it install the addiional packages automatically?\n",
    "    I did not evaluate this\n",
    "\n",
    "The main.py for the cif-cn-featurizer was modified by setting script_directory to the HW2 folder that contained the cifs folder for this homework question.\n",
    "Then was run from the command line.\n",
    "\n",
    "A try - except block was added to the cif-cn-featurizer main.py to skip files that had issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code was either added or commented out in the original main.py for the cn-cif-featurizer\n",
    " \n",
    "# # script_directory = os.path.dirname(os.path.abspath(__file__))    \n",
    "# script_directory = r\"C:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\"\n",
    "# cif_folder_directory = folder.choose_CIF_directory(script_directory)\n",
    "\n",
    "# # I used the above, but my resulting file was not in the folder I wanted\n",
    "# # I believe the below line will fix that so I don't have to move it later, but I did not test it\n",
    "# cif_folder_directory = os.path.join(script_directory, \"csv\")\n",
    "\n",
    "\n",
    "# # generate an error file for any errors in processing cif files\n",
    "    # error_log_file = os.path.join(script_directory, 'cif-cn-featurizer-errors.csv')\n",
    "\n",
    "\n",
    "## Added the try statement in this for loop\n",
    "    # for idx, filename in enumerate(files_lst, start=1):\n",
    "    #     try:\n",
    "    #         start_time = time.time()\n",
    "## ..\n",
    "# #..\n",
    "## ..\n",
    "\n",
    "    #    except Exception as e:\n",
    "    #         error_message = f\"Could not process {filename}. Error: {e}\"\n",
    "    #         print(error_message)\n",
    "    #         # write the error to the file\n",
    "    #         with open(error_log_file, 'a') as file:\n",
    "    #             filename_base = os.path.basename(filename)\n",
    "    #             file.write(f'\"{filename_base}\",\"{error_message}\"\\n')\n",
    "        \n",
    "    #         continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\byron\\AppData\\Local\\Temp\\ipykernel_12040\\2871664664.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Read the error file\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "# df = pd.dataframe()\n",
    "\n",
    "csv_file_path = r\"C:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\csv\"\n",
    "error_file = csv_file_path + \"\\cif-cn-featurizer-errors.csv\"\n",
    "error_df = pd.read_csv(error_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Filename        Error\n",
      "0   250022.cif  Error: 'Nb'\n",
      "1   250065.cif  Error: 'Mo'\n",
      "2   250125.cif  Error: 'Mo'\n",
      "3   250186.cif  Error: 'Mo'\n",
      "4   250191.cif  Error: 'Mo'\n",
      "5   250223.cif  Error: 'Nb'\n",
      "6   250225.cif  Error: 'Mo'\n",
      "7   250236.cif  Error: 'Nb'\n",
      "8   250390.cif  Error: 'Mo'\n",
      "9   250399.cif   Error: 'V'\n",
      "10  250476.cif  Error: 'Pb'\n",
      "11  250477.cif  Error: 'Pb'\n",
      "12  250525.cif  Error: 'Ti'\n",
      "13  250527.cif  Error: 'Pb'\n",
      "14  250530.cif  Error: 'Nb'\n",
      "15  250561.cif   Error: 'W'\n",
      "16  250562.cif   Error: 'W'\n",
      "17  250563.cif  Error: 'Mo'\n",
      "18  250564.cif  Error: 'Mo'\n",
      "19  250628.cif  Error: 'Nb'\n",
      "20  250679.cif  Error: 'Pb'\n",
      "21  250733.cif  Error: 'Ta'\n",
      "22  250735.cif  Error: 'Nb'\n",
      "23  250737.cif  Error: 'Ta'\n",
      "24  250740.cif   Error: 'V'\n",
      "25  250742.cif   Error: 'V'\n",
      "26  250751.cif  Error: 'Au'\n",
      "27  250752.cif  Error: 'Au'\n",
      "28  250753.cif  Error: 'Au'\n",
      "29  250754.cif  Error: 'Au'\n",
      "30  250755.cif  Error: 'Au'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The error message has the full path name\n",
    "# Truncate it and put it in 'Error' for easier reading\n",
    "error_df['Error'] = error_df['Error Message'].apply(lambda x: x[-11:])\n",
    "\n",
    "# Display all cif files and the error message\n",
    "print(error_df[['Filename','Error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Error  Count\n",
      "0  Error: 'Mo'      8\n",
      "1  Error: 'Nb'      6\n",
      "2  Error: 'Au'      5\n",
      "3  Error: 'Pb'      4\n",
      "4   Error: 'V'      3\n",
      "5   Error: 'W'      2\n",
      "6  Error: 'Ta'      2\n",
      "7  Error: 'Ti'      1\n"
     ]
    }
   ],
   "source": [
    "# I had ChatGPT 3.5 write me the code to \n",
    "# get a new df that has the unique Error with a count of how many records in my error_df have that Error\n",
    "\n",
    "# Get counts of each unique error\n",
    "error_counts = error_df[\"Error\"].value_counts()\n",
    "\n",
    "# Create a new DataFrame with unique errors and their counts\n",
    "unique_errors_df = pd.DataFrame({\"Error\": error_counts.index, \"Count\": error_counts.values})\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(unique_errors_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking through the main.py and the file structure of the repository it seems clear that the scripts are pulling data from the Excel file and using it to generate the features for binary and ternary systems.\n",
    "\n",
    "The _featurizer_log.csv that was supplied with the CIF files has records of successfully processing most of the CIF files.\n",
    "When I run the featurizer, it fails to process 31 of the files.\n",
    "\n",
    "It seems that they were processed with a property file that was more complete than the one available on the repository\n",
    "\n",
    "126 CIF files were received, but only 124 were processed (according to the log.csv file)\n",
    "Which 2 files were not processed?\n",
    "\n",
    "All of the W and Ta files that failed for me were successfully processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 Getting labeled data for the cifs**\n",
    "\n",
    "**<font color='teal'>b)</font>** Now that you've got feature vectors in a series of .csv files, let's use them to build a model to predict a property. To get a property let's search for a materials project entry using the cif cards! If you've forgotten how, go back to the `legacy_MPRester_tutorial.ipynb` notebook where we did an example. Once you have the material project id, run a query to extract a property like bulk modulus ([\"elasticity\"][\"K_VRH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'phonopy'\n",
      "No module named 'phonopy'\n"
     ]
    }
   ],
   "source": [
    "# Set up my MP Rester with my API key\n",
    "\n",
    "from mp_api.client import MPRester\n",
    "import os\n",
    "\n",
    "#set path to text file with the MP API key\n",
    "filename = r'C:\\Users\\byron\\OneDrive\\Documents\\Byron School\\Materials Informatics\\MP-apikey.txt'\n",
    "\n",
    "def get_file_contents(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            # It's assumed our file contains a single line,\n",
    "            # with our API key\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(\"'%s' file not found\" % filename)\n",
    "\n",
    "#set MP_APIKEY to the key\n",
    "MP_APIKEY = get_file_contents(filename)\n",
    "\n",
    "#set mpr as the MPRester to simplify later code\n",
    "mpr = MPRester(MP_APIKEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250022.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250065.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250101.cif.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\byron\\miniconda3\\envs\\HW2\\lib\\site-packages\\pymatgen\\io\\cif.py:1224: UserWarning: Issues encountered while parsing CIF: 3 fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: \" + \"\\n\".join(self.warnings))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250125.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250186.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250191.cif.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\byron\\miniconda3\\envs\\HW2\\lib\\site-packages\\pymatgen\\io\\cif.py:1224: UserWarning: Issues encountered while parsing CIF: 4 fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: \" + \"\\n\".join(self.warnings))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250223.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250225.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250236.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250328.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250329.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250330.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250331.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250332.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250333.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250334.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250335.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250336.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250337.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250338.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250339.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250340.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250363.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250364.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250365.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250366.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250367.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250368.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250369.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250370.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250372.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250373.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250374.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250375.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250376.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250377.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250378.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250379.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250380.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250381.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250382.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250383.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250384.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250385.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250390.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250394.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250399.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250404.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250410.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250411.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250460.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250461.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250462.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250463.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250464.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250465.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250468.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250469.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250476.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250477.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250502.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250503.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250504.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250505.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250506.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250507.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250508.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250525.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250527.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250530.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250554.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250561.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250562.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250563.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250564.cif.\n",
      "Error processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250615.cif. Error is Invalid CIF file with no structures!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\byron\\miniconda3\\envs\\HW2\\lib\\site-packages\\pymatgen\\io\\cif.py:762: UserWarning: No _symmetry_equiv_pos_as_xyz type key found. Defaulting to P1.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\byron\\miniconda3\\envs\\HW2\\lib\\site-packages\\pymatgen\\io\\cif.py:1218: UserWarning: No structure parsed for section 1 in CIF.\n",
      "'_atom_site_label'\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\byron\\miniconda3\\envs\\HW2\\lib\\site-packages\\pymatgen\\io\\cif.py:1224: UserWarning: Issues encountered while parsing CIF: No _symmetry_equiv_pos_as_xyz type key found. Defaulting to P1.\n",
      "No structure parsed for section 1 in CIF.\n",
      "'_atom_site_label'\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: \" + \"\\n\".join(self.warnings))\n",
      "c:\\Users\\byron\\miniconda3\\envs\\HW2\\lib\\site-packages\\pymatgen\\io\\cif.py:1224: UserWarning: Issues encountered while parsing CIF: 6 fractional coordinates rounded to ideal values to avoid issues with finite precision.\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: \" + \"\\n\".join(self.warnings))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250628.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250646.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250647.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250648.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250649.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250650.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250651.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250652.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250653.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250654.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250668.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250679.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250693.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250717.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250718.cif.\n",
      "Error processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250732.cif. Error is Invalid CIF file with no structures!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\byron\\miniconda3\\envs\\HW2\\lib\\site-packages\\pymatgen\\io\\cif.py:1224: UserWarning: Issues encountered while parsing CIF: No structure parsed for section 1 in CIF.\n",
      "'_atom_site_label'\n",
      "  warnings.warn(\"Issues encountered while parsing CIF: \" + \"\\n\".join(self.warnings))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250733.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250735.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250737.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250740.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250742.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250751.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250752.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250753.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250754.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250755.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250763.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250765.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250804.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250805.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250806.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250807.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250808.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250809.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250810.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250811.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250891.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250892.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250893.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250894.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250907.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250910.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250920.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250931.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250934.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250959.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250962.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250963.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250966.cif.\n",
      "Success processing c:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\250977.cif.\n"
     ]
    }
   ],
   "source": [
    "#pull mpid files from the mp database for each cif file in the cifs folder\n",
    "import os\n",
    "\n",
    "# get a list of all cif files\n",
    "script_directory = os.getcwd()\n",
    "cif_path = os.path.join(script_directory,'cn-featurizer\\cifs')\n",
    "all_files = os.listdir(cif_path)\n",
    "cif_files = [os.path.join(cif_path, file) for file in all_files if file.endswith('.cif')]\n",
    "\n",
    "# In HW1 I used the following line successfully\n",
    "# 2/18:  I keep getting 504 time out errors so I expaneded the for loop to print \n",
    "# Successes and failures\n",
    "# list = [mpr.find_structure(cif_file) for cif_file in cif_files]\n",
    "# Encapsulated in a for loop in order to add a try except to log successes and failures\n",
    "\n",
    "# bulk modulus ([\"elasticity\"][\"K_VRH\"])\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Initialize an empty DataFrame with columns for cif_file and mpid\n",
    "mpid_records = pd.DataFrame(columns=['cif_file', 'mpid'])\n",
    "\n",
    "for cif_file in cif_files:\n",
    "    try:\n",
    "        mpid = mpr.find_structure(cif_file)\n",
    "        # Append the new record to the DataFrame\n",
    "        new_mpid = pd.DataFrame({'cif_file': [os.path.basename(cif_file)],'mpid': [mpid]})\n",
    "        mpid_records = pd.concat([mpid_records,new_mpid],ignore_index=True )\n",
    "        # mpid_records_df = mpid_records_df.append({'cif_file': os.path.basename(cif_file), 'mpid': mpid}, ignore_index=True)\n",
    "        print(f\"Success processing {cif_file}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {cif_file}. Error is {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above was saved to mpr_log.txt so I can go back through the errors and either look for or fix cif files that returned errors, it could just be a minor formatting issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter mpid_records into success and error\n",
    "mpid_records_success = mpid_records[mpid_records['mpid'].astype(bool)]\n",
    "mpid_records_error = mpid_records[~mpid_records['mpid'].astype(bool)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9662d6dd5cd6419489239c82752c32b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving SummaryDoc documents:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pull the density of each mpid\n",
    "mpids = mpid_records_success['mpid'].tolist()\n",
    "\n",
    "docs = mpr.materials.summary.search(material_ids=mpids,\n",
    "                                    fields=[\"material_id\",\n",
    "                                            \"formula_pretty\",\n",
    "                                            \"density\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 92 records pulled from the mpids list\n",
    "There are 105 mpids in the list indicating there are several duplicate values\n",
    "Data Wrangler indicates there are 86 distinct mpids so it is unclear why we got 92 records for 86 unique ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MPID(mp-20131),\n",
       " MPID(mp-20729),\n",
       " MPID(mp-20369),\n",
       " MPID(mp-20903),\n",
       " MPID(mp-21197),\n",
       " MPID(mp-20258),\n",
       " MPID(mp-20920),\n",
       " MPID(mp-20236),\n",
       " MPID(mp-21431),\n",
       " MPID(mp-1291),\n",
       " MPID(mp-21177),\n",
       " MPID(mp-977),\n",
       " MPID(mp-801),\n",
       " MPID(mp-22568),\n",
       " MPID(mp-16513),\n",
       " MPID(mp-865411),\n",
       " MPID(mp-1080098),\n",
       " MPID(mp-1101986),\n",
       " MPID(mp-1102392),\n",
       " MPID(mp-2588),\n",
       " MPID(mp-569196),\n",
       " MPID(mp-19977),\n",
       " MPID(mp-1051),\n",
       " MPID(mp-20309),\n",
       " MPID(mp-2451),\n",
       " MPID(mp-865411),\n",
       " MPID(mp-16513),\n",
       " MPID(mp-12553),\n",
       " MPID(mp-567305),\n",
       " MPID(mp-959),\n",
       " MPID(mp-2134),\n",
       " MPID(mp-1409),\n",
       " MPID(mp-21432),\n",
       " MPID(mp-1451),\n",
       " MPID(mp-30745),\n",
       " MPID(mp-30866),\n",
       " MPID(mp-11482),\n",
       " MPID(mp-30787),\n",
       " MPID(mp-2351),\n",
       " MPID(mp-790),\n",
       " MPID(mp-481),\n",
       " MPID(mp-2092),\n",
       " MPID(mp-21427),\n",
       " MPID(mp-718),\n",
       " MPID(mp-640095),\n",
       " MPID(mp-20309),\n",
       " MPID(mp-369),\n",
       " MPID(mp-865411),\n",
       " MPID(mp-1451),\n",
       " MPID(mp-891),\n",
       " MPID(mp-1082),\n",
       " MPID(mp-2006),\n",
       " MPID(mp-1080590),\n",
       " MPID(mp-30386),\n",
       " MPID(mp-1080756),\n",
       " MPID(mp-980752),\n",
       " MPID(mp-1101053),\n",
       " MPID(mp-2465),\n",
       " MPID(mp-1549),\n",
       " MPID(mp-674),\n",
       " MPID(mp-2092),\n",
       " MPID(mp-1571),\n",
       " MPID(mp-559),\n",
       " MPID(mp-30634),\n",
       " MPID(mp-718),\n",
       " MPID(mp-20971),\n",
       " MPID(mp-20516),\n",
       " MPID(mp-801),\n",
       " MPID(mp-768),\n",
       " MPID(mp-1139),\n",
       " MPID(mp-1232),\n",
       " MPID(mp-11506),\n",
       " MPID(mp-1326),\n",
       " MPID(mp-674),\n",
       " MPID(mp-2092),\n",
       " MPID(mp-1571),\n",
       " MPID(mp-2333),\n",
       " MPID(mp-357),\n",
       " MPID(mp-636279),\n",
       " MPID(mp-21427),\n",
       " MPID(mp-2747),\n",
       " MPID(mp-797),\n",
       " MPID(mp-1979),\n",
       " MPID(mp-2825),\n",
       " MPID(mp-1158),\n",
       " MPID(mp-633),\n",
       " MPID(mp-1911),\n",
       " MPID(mp-376),\n",
       " MPID(mp-1977),\n",
       " MPID(mp-2484),\n",
       " MPID(mp-20387),\n",
       " MPID(mp-19919)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpids = [doc.material_id for doc in docs]\n",
    "mpids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\byron\\AppData\\Local\\Temp\\ipykernel_12040\\2653422538.py:7: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  mpdata_df = pd.concat([mpdata_df,new_record],ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Generate a df of the data pulled from the Material Project\n",
    "import pandas as pd\n",
    "\n",
    "mpdata_df = pd.DataFrame(columns=['mpid','formula','density'])\n",
    "for doc in docs:\n",
    "    new_record = pd.DataFrame({'mpid':[doc.material_id],'formula':[doc.formula_pretty],'density':[doc.density]})\n",
    "    mpdata_df = pd.concat([mpdata_df,new_record],ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpid</th>\n",
       "      <th>formula</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mp-20131</td>\n",
       "      <td>YIn3</td>\n",
       "      <td>7.270778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mp-20729</td>\n",
       "      <td>LaIn3</td>\n",
       "      <td>7.376636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mp-20369</td>\n",
       "      <td>CeIn3</td>\n",
       "      <td>7.775450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mp-20903</td>\n",
       "      <td>PrIn3</td>\n",
       "      <td>7.656969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mp-21197</td>\n",
       "      <td>NdIn3</td>\n",
       "      <td>7.823092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>mp-376</td>\n",
       "      <td>PrSn3</td>\n",
       "      <td>7.546256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>mp-1977</td>\n",
       "      <td>NdSn3</td>\n",
       "      <td>7.691879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>mp-2484</td>\n",
       "      <td>SmSn3</td>\n",
       "      <td>7.930209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>mp-20387</td>\n",
       "      <td>EuSn3</td>\n",
       "      <td>7.801257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>mp-19919</td>\n",
       "      <td>GdSn3</td>\n",
       "      <td>8.156980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mpid formula   density\n",
       "0   mp-20131    YIn3  7.270778\n",
       "1   mp-20729   LaIn3  7.376636\n",
       "2   mp-20369   CeIn3  7.775450\n",
       "3   mp-20903   PrIn3  7.656969\n",
       "4   mp-21197   NdIn3  7.823092\n",
       "..       ...     ...       ...\n",
       "87    mp-376   PrSn3  7.546256\n",
       "88   mp-1977   NdSn3  7.691879\n",
       "89   mp-2484   SmSn3  7.930209\n",
       "90  mp-20387   EuSn3  7.801257\n",
       "91  mp-19919   GdSn3  8.156980\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate mpids\n",
    "mpdata_df = mpdata_df.drop_duplicates()\n",
    "mpdata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MPID records I pulled for the CIF files need to be tied to the featurizer data in the CSV files\n",
    "Need to query these CSV files with the formulae in my docs to relate the density I pulled from mprester to the features generated by the cif featurizer\n",
    "\n",
    "The following CSV files were generated by the featurizer:\n",
    "    -   cifs_atomic_environment_features_binary\n",
    "    -   cifs_atomic_environment_wyckoff_multiplicity_features_binary\n",
    "    -   cifs_atomic_environment_wyckoff_multiplicity_features_universal\n",
    "    -   cifs_coordination_number_binary_all\n",
    "    -   cifs_coordination_number_binary_avg\n",
    "    -   cifs_coordination_number_binary_max\n",
    "    -   cifs_coordination_number_binary_min\n",
    "    -   cifs_interatomic_features_binary\n",
    "    -   cifs_interatomic_features_universal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the mpid_record_success which has CIF files with MPIDs with the mpdata_df that has the formula and density\n",
    "\n",
    "cif_data_df = pd.merge(mpid_records_success,mpdata_df[['mpid','formula','density']],on='mpid',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\byron\\AppData\\Local\\Temp\\ipykernel_12040\\1677030793.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cif_data_scrubbed['CIF_id']= cif_data_scrubbed['cif_file'].str.replace('.cif', '', regex=False)\n",
      "C:\\Users\\byron\\AppData\\Local\\Temp\\ipykernel_12040\\1677030793.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cif_data_scrubbed['CIF_id'] = cif_data_scrubbed['CIF_id'].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cif_file</th>\n",
       "      <th>mpid</th>\n",
       "      <th>formula</th>\n",
       "      <th>density</th>\n",
       "      <th>CIF_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250065.cif</td>\n",
       "      <td>mp-801</td>\n",
       "      <td>Mo3Os</td>\n",
       "      <td>12.883572</td>\n",
       "      <td>250065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>250101.cif</td>\n",
       "      <td>mp-768</td>\n",
       "      <td>TmAl3</td>\n",
       "      <td>5.632610</td>\n",
       "      <td>250101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250125.cif</td>\n",
       "      <td>mp-1139</td>\n",
       "      <td>Co3Mo</td>\n",
       "      <td>9.962997</td>\n",
       "      <td>250125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250191.cif</td>\n",
       "      <td>mp-1232</td>\n",
       "      <td>Mo3Pt</td>\n",
       "      <td>12.898261</td>\n",
       "      <td>250191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250225.cif</td>\n",
       "      <td>mp-11506</td>\n",
       "      <td>Ni3Mo</td>\n",
       "      <td>9.769614</td>\n",
       "      <td>250225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>250920.cif</td>\n",
       "      <td>mp-30634</td>\n",
       "      <td>HoFe3</td>\n",
       "      <td>8.915389</td>\n",
       "      <td>250920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>250934.cif</td>\n",
       "      <td>mp-718</td>\n",
       "      <td>SnPd3</td>\n",
       "      <td>11.303794</td>\n",
       "      <td>250934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>250962.cif</td>\n",
       "      <td>mp-20971</td>\n",
       "      <td>SnPt3</td>\n",
       "      <td>17.869663</td>\n",
       "      <td>250962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>250963.cif</td>\n",
       "      <td>mp-20516</td>\n",
       "      <td>InPt3</td>\n",
       "      <td>17.912752</td>\n",
       "      <td>250963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>250977.cif</td>\n",
       "      <td>mp-1051</td>\n",
       "      <td>ErNi3</td>\n",
       "      <td>10.347703</td>\n",
       "      <td>250977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cif_file      mpid formula    density  CIF_id\n",
       "0    250065.cif    mp-801   Mo3Os  12.883572  250065\n",
       "1    250101.cif    mp-768   TmAl3   5.632610  250101\n",
       "2    250125.cif   mp-1139   Co3Mo   9.962997  250125\n",
       "3    250191.cif   mp-1232   Mo3Pt  12.898261  250191\n",
       "4    250225.cif  mp-11506   Ni3Mo   9.769614  250225\n",
       "..          ...       ...     ...        ...     ...\n",
       "99   250920.cif  mp-30634   HoFe3   8.915389  250920\n",
       "101  250934.cif    mp-718   SnPd3  11.303794  250934\n",
       "102  250962.cif  mp-20971   SnPt3  17.869663  250962\n",
       "103  250963.cif  mp-20516   InPt3  17.912752  250963\n",
       "104  250977.cif   mp-1051   ErNi3  10.347703  250977\n",
       "\n",
       "[95 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cif_data_df now has a list of all cif_files where an mpid was found \n",
    "# looking through we can now see which records are missing formula and density data which\n",
    "# tells us which records failed to pull from the Materials Project\n",
    "\n",
    "# scrub the NaN records\n",
    "cif_data_scrubbed = cif_data_df.dropna()\n",
    "# record the CIF_id from each cif_file and convert to an integer\n",
    "cif_data_scrubbed['CIF_id']= cif_data_scrubbed['cif_file'].str.replace('.cif', '', regex=False)\n",
    "cif_data_scrubbed['CIF_id'] = cif_data_scrubbed['CIF_id'].astype(int)\n",
    "cif_data_scrubbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have a dataframe, cif_data_scrubbed, which has all the information I Need to merge with the features that are in the CSV files by CIFID\n",
    "\n",
    "In the code block below, the features are pulled in from the CSV files\n",
    "Initially I pulled in all the CSV files that I put into feature_files but the number of rows ended up growing exponentially\n",
    "This is due to some of the csv files containing multiple rows for each cif_id\n",
    "Not 100% sure how to reconcile that in a SVM model, \n",
    "I was under the impression that the featurizer would add many columns as features for a single row \n",
    "The commented out files below are those that had multiple rows per cif_id\n",
    "\n",
    "Will use the other features in my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# This was also set above, but including it here again for ease of reusing thsi code at a later time possibly\n",
    "csv_file_path = r\"C:\\Users\\byron\\OneDrive\\Documents\\GitHub\\MaterialsInformatics\\byron\\HW2\\cn-featurizer\\cifs\\csv\"\n",
    "\n",
    "# list of the csv files with all of the structural features\n",
    "feature_files = [\n",
    "    \"cifs_atomic_environment_features_binary.csv\",                          # 0 *\n",
    "    # \"cifs_atomic_environment_wyckoff_multiplicity_features_binary.csv\",     # 1 *\n",
    "    # \"cifs_atomic_environment_wyckoff_multiplicity_features_universal.csv\",  # 2 *\n",
    "    # \"cifs_coordination_number_binary_all.csv\",                              # 3\n",
    "    # \"cifs_coordination_number_binary_avg.csv\",                              # 4\n",
    "    # \"cifs_coordination_number_binary_max.csv\",                              # 5\n",
    "    # \"cifs_coordination_number_binary_min.csv\",                              # 6\n",
    "    \"cifs_interatomic_features_binary.csv\",                                 # 7 **\n",
    "    \"cifs_interatomic_features_universal.csv\"                               # 8 **\n",
    "]\n",
    "\n",
    "features_df = cif_data_scrubbed.copy()\n",
    "for file in feature_files:\n",
    "    file_path = os.path.join(csv_file_path,file)\n",
    "    file_df = pd.read_csv(file_path)\n",
    "    features_df = pd.merge(features_df, file_df, on=\"CIF_id\",how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cif_data_scrubbed shape =  {(95, 5)}\n",
      "features_df shape =  {(95, 67)}\n"
     ]
    }
   ],
   "source": [
    "print(f\"cif_data_scrubbed shape = \",{cif_data_scrubbed.shape})\n",
    "print(f\"features_df shape = \",{features_df.shape})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, my cif_data_scrubbed df has the cif_file, cif_id, formula, mpid, and density for each CIF file where this data was found.\n",
    "My features_df has all those columns plus the structural features produced by the cif-cn-featurizer\n",
    "    The feature csv files that had multiple rows per cif file were excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 Comparing structural features to compositional features**\n",
    "\n",
    "**<font color='teal'>c)</font>** Now that you've got structural features and you can get compositional features (use CBFV), let's compare them! Build a Support vector machine regressor model with each feature set and determine which works better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a new df to use for cbfv featuring\n",
    "cbfv_unfeatured_df = cif_data_scrubbed[['formula','density']].copy().rename(columns={'density':'target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████| 95/95 [00:00<00:00, 8550.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████| 95/95 [00:00<00:00, 6114.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate features using CBFV\n",
    "\n",
    "from CBFV import composition\n",
    "feature_model = 'oliynyk'       #explicitly set the featurizer model 'oliynyk is the default, but I'm setting it explicitly anyway\n",
    "X, y, formulae, skipped = composition.generate_features(cbfv_unfeatured_df,elem_prop=feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is 0.9948482146436889\n",
      "the mean absolute error is 0.15708938688275234\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# scale and normalize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "scaler = StandardScaler()   # Set up the scaler as the STandardScaler\n",
    "\n",
    "RNG_SEED = 42\n",
    "np.random.seed(seed=RNG_SEED)\n",
    "\n",
    "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RNG_SEED)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_unscaled)       #the train and val splits were done on unscaled data\n",
    "X_test = scaler.transform(X_test_unscaled)\n",
    " \n",
    "# Normalize all of the X datasets\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "\n",
    "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('the r2 score is',r2)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('the mean absolute error is',mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r2 score is 0.8338439171696592\n",
      "the mean absolute error is 1.1292359041264897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\byron\\miniconda3\\envs\\HW2\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Now need to split the cif-cn-featurizer data in features_df \n",
    "\n",
    "features_df_dropna = features_df.dropna()\n",
    "y_cn = features_df_dropna[['density']].copy()\n",
    "X_cn = features_df_dropna.drop(columns=['density','cif_file','mpid','formula','Compound','Compound_x','A_x','B_x','Compound_y','A_y','B_y']).copy()\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RNG_SEED = 42\n",
    "np.random.seed(seed=RNG_SEED)\n",
    "\n",
    "X_train_cn, X_test_cn, y_train_cn, y_test_cn = train_test_split(X_cn, y_cn, test_size=0.33, random_state=RNG_SEED)\n",
    "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr.fit(X_train_cn, y_train_cn)\n",
    "\n",
    "y_pred_cn = svr.predict(X_test_cn)\n",
    "r2 = r2_score(y_test_cn, y_pred_cn)\n",
    "print('the r2 score is',r2)\n",
    "mae = mean_absolute_error(y_test_cn, y_pred_cn)\n",
    "print('the mean absolute error is',mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9932120519360371\n",
      "Mean Absolute Error: 0.21225614785733807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\byron\\miniconda3\\envs\\HW2\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.462e-01, tolerance: 1.097e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "scaler = StandardScaler()   # Set up the scaler as the STandardScaler\n",
    "\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_unscaled)       #the train and val splits were done on unscaled data\n",
    "X_test = scaler.transform(X_test_unscaled)\n",
    " \n",
    "# Normalize all of the X datasets\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)\n",
    "\n",
    "# Feature selection with Lasso\n",
    "lasso = Lasso(alpha=0.001)  # You can adjust the regularization strength\n",
    "lasso.fit(X_train, y_train)\n",
    "selected_features = np.where(lasso.coef_ != 0)[0]  # Indices of selected features\n",
    "\n",
    "# Use selected features to train SVR model\n",
    "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr.fit(X_train[:, selected_features], y_train)\n",
    "\n",
    "# Predict target values using SVR model\n",
    "y_pred = svr.predict(X_test[:, selected_features])\n",
    "\n",
    "# Evaluate SVR model performance\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 score:', r2)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Mean Absolute Error:', mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha 0.2: R2 = 0.971, MAE = 0.4584\n",
    "alpha 0.1: R2 = 0.971, MAE = 0.4584\n",
    "alpha 0.01: R2 = 0.985, MAE = 0.3032\n",
    "alpha 0.001: R2 = 0.993, MAE = 0.2123\n",
    "\n",
    "At alpha at 0.3 and higher, it fails with 0 features\n",
    "\n",
    "Unclear if we are overfitting as alpha decreases.\n",
    "\n",
    "The code should be modified to perform cross-validation to ensure we don't over fit\n",
    "Should also use a search method for hyperparameter optimization on the lasso regularization and for SVR parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
